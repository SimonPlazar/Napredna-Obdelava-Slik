{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-23T14:25:39.615950Z",
     "start_time": "2025-10-23T14:25:37.309535Z"
    }
   },
   "source": [
    "# FINAL DATASET\n",
    "\n",
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"ll01dm/t91-image-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\simon\\.cache\\kagglehub\\datasets\\ll01dm\\t91-image-dataset\\versions\\1\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T14:39:22.904453Z",
     "start_time": "2025-10-23T14:39:14.954069Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def analyze_dataset(dir_path):\n",
    "    total_w = total_h = count = 0\n",
    "\n",
    "    for root, _, files in os.walk(dir_path):\n",
    "        for fname in files:\n",
    "            fp = os.path.join(root, fname)\n",
    "            try:\n",
    "                img = cv2.imread(fp)\n",
    "                if img is None:\n",
    "                    continue\n",
    "                h, w = img.shape[:2]\n",
    "                total_w += w\n",
    "                total_h += h\n",
    "                count += 1\n",
    "            except Exception:\n",
    "                # skip unreadable files\n",
    "                continue\n",
    "\n",
    "    if count == 0:\n",
    "        print(f\"No images found in {dir_path!r}\")\n",
    "        return\n",
    "\n",
    "    avg_w = total_w / count\n",
    "    avg_h = total_h / count\n",
    "    print(f\"Dataset: {dir_path}\")\n",
    "    print(f\"Number of images: {count}\")\n",
    "    print(f\"Average width: {avg_w:.2f}\")\n",
    "    print(f\"Average height: {avg_h:.2f}\")\n",
    "\n",
    "\n",
    "analyze_dataset(path)"
   ],
   "id": "eb470a1820c0a70",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: C:\\Users\\simon\\.cache\\kagglehub\\datasets\\ll01dm\\t91-image-dataset\\versions\\1\n",
      "Number of images: 182\n",
      "Average width: 264.12\n",
      "Average height: 203.58\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T14:49:54.631012Z",
     "start_time": "2025-10-23T14:49:50.555036Z"
    }
   },
   "cell_type": "code",
   "source": [
    "downscale_factor = 2\n",
    "\n",
    "def resize_images(input_dir, output_dir, downscale_factor):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for root, _, files in os.walk(input_dir):\n",
    "        for fname in files:\n",
    "            input_fp = os.path.join(root, fname)\n",
    "            relative_path = os.path.relpath(root, input_dir)\n",
    "            output_subdir = os.path.join(output_dir, str(relative_path))\n",
    "            os.makedirs(output_subdir, exist_ok=True)\n",
    "            output_fp = os.path.join(output_subdir, str(fname))\n",
    "\n",
    "            try:\n",
    "                img = cv2.imread(input_fp)\n",
    "                if img is None:\n",
    "                    continue\n",
    "                h, w = img.shape[:2]\n",
    "                new_w = max(1, int(w / downscale_factor))\n",
    "                new_h = max(1, int(h / downscale_factor))\n",
    "                img_resized = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_LINEAR)\n",
    "                cv2.imwrite(output_fp, img_resized)\n",
    "            except Exception:\n",
    "                # skip unreadable files\n",
    "                continue\n",
    "\n",
    "datasets_folder = \"datasets\"\n",
    "\n",
    "output_path = os.path.join(datasets_folder, f\"t91-image-dataset-x{downscale_factor}\")\n",
    "\n",
    "resize_images(path, output_path, downscale_factor)\n",
    "print(\"Resized images saved to:\", output_path)\n"
   ],
   "id": "237ae5ba92685fe0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resized images saved to: datasets\\t91-image-dataset-x2\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def rgb_to_ycbcr(img):\n",
    "    \"\"\"\n",
    "    Convert RGB image to YCbCr color space.\n",
    "\n",
    "    Args:\n",
    "        img: RGB image as numpy array (H, W, 3) with values in [0, 255]\n",
    "\n",
    "    Returns:\n",
    "        YCbCr image as numpy array (H, W, 3) with Y in [16, 235], Cb/Cr in [16, 240]\n",
    "    \"\"\"\n",
    "    # OpenCV uses BGR, so convert RGB to BGR first, then to YCrCb (OpenCV's YCbCr)\n",
    "    img_bgr = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "    img_ycbcr = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2YCrCb)\n",
    "\n",
    "    return img_ycbcr\n",
    "\n",
    "def ycbcr_to_rgb(img):\n",
    "    \"\"\"\n",
    "    Convert YCbCr image back to RGB color space.\n",
    "\n",
    "    Args:\n",
    "        img: YCbCr image as numpy array (H, W, 3)\n",
    "\n",
    "    Returns:\n",
    "        RGB image as numpy array (H, W, 3) with values in [0, 255]\n",
    "    \"\"\"\n",
    "    # OpenCV YCrCb to BGR, then BGR to RGB\n",
    "    img_bgr = cv2.cvtColor(img, cv2.COLOR_YCrCb2BGR)\n",
    "    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    return img_rgb\n",
    "\n",
    "def extract_y_channel(img_ycbcr):\n",
    "    \"\"\"\n",
    "    Extract only the Y (luminance) channel from YCbCr image.\n",
    "    This channel will be used as input/output for the neural network.\n",
    "\n",
    "    Args:\n",
    "        img_ycbcr: YCbCr image as numpy array (H, W, 3)\n",
    "\n",
    "    Returns:\n",
    "        Y channel as numpy array (H, W) or (H, W, 1)\n",
    "    \"\"\"\n",
    "    return img_ycbcr[:, :, 0]\n",
    "\n",
    "def reconstruct_rgb(y_channel_hr, img_lr, target_size):\n",
    "    \"\"\"\n",
    "    Reconstruct full RGB image by combining high-res Y channel from the network\n",
    "    with interpolated Cb/Cr channels from the low-resolution image.\n",
    "\n",
    "    Args:\n",
    "        y_channel_hr: High-resolution Y channel output from network (H, W) or (H, W, 1)\n",
    "        img_lr: Low-resolution RGB image (h, w, 3)\n",
    "        target_size: Target size (width, height) for the output image\n",
    "\n",
    "    Returns:\n",
    "        Reconstructed high-resolution RGB image (H, W, 3)\n",
    "    \"\"\"\n",
    "    # Convert low-res RGB to YCbCr\n",
    "    img_lr_ycbcr = rgb_to_ycbcr(img_lr)\n",
    "\n",
    "    # Extract Cb and Cr channels from low-res image\n",
    "    cb_lr = img_lr_ycbcr[:, :, 1]\n",
    "    cr_lr = img_lr_ycbcr[:, :, 2]\n",
    "\n",
    "    # Interpolate Cb and Cr to match high-res size using bilinear interpolation\n",
    "    cb_hr = cv2.resize(cb_lr, target_size, interpolation=cv2.INTER_LINEAR)\n",
    "    cr_hr = cv2.resize(cr_lr, target_size, interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    # Ensure Y channel has correct shape\n",
    "    if len(y_channel_hr.shape) == 3 and y_channel_hr.shape[2] == 1:\n",
    "        y_channel_hr = y_channel_hr[:, :, 0]\n",
    "\n",
    "    # Combine Y, Cb, Cr channels\n",
    "    img_hr_ycbcr = np.stack([y_channel_hr, cb_hr, cr_hr], axis=2).astype(np.uint8)\n",
    "\n",
    "    # Convert back to RGB\n",
    "    img_hr_rgb = ycbcr_to_rgb(img_hr_ycbcr)\n",
    "\n",
    "    return img_hr_rgb\n",
    "\n",
    "\n",
    "# Example usage with OpenCV:\n",
    "# 1. Convert high-res training image to YCbCr and extract Y channel\n",
    "#    img_hr_bgr = cv2.imread(\"high_res.png\")\n",
    "#    img_hr_rgb = cv2.cvtColor(img_hr_bgr, cv2.COLOR_BGR2RGB)\n",
    "#    img_hr_ycbcr = rgb_to_ycbcr(img_hr_rgb)\n",
    "#    y_hr = extract_y_channel(img_hr_ycbcr)  # This is the ground truth for training\n",
    "#\n",
    "# 2. Convert low-res input to YCbCr and extract Y channel for network input\n",
    "#    h, w = img_hr_rgb.shape[:2]\n",
    "#    img_lr_rgb = cv2.resize(img_hr_rgb, (w//2, h//2), interpolation=cv2.INTER_LINEAR)\n",
    "#    img_lr_ycbcr = rgb_to_ycbcr(img_lr_rgb)\n",
    "#    y_lr = extract_y_channel(img_lr_ycbcr)  # This is the input to the network\n",
    "#\n",
    "# 3. After network inference, reconstruct RGB from Y channel output\n",
    "#    y_output = model.predict(y_lr)  # Network output (high-res Y channel)\n",
    "#    img_reconstructed = reconstruct_rgb(y_output, img_lr_rgb, (w, h))\n"
   ],
   "id": "b5b1a513b041e1bb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
